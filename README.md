# 回归分析
*Application of data mining with regression analysis.*

在我们的日常生活中，经常会出现某一变量受到其他变量影响的情况，回归分析就是研究一个变量Y和一或多个自变量X之间的关系。线性回归通常在学习预测模型时首选的技术之一。其中，因变量是连续的，自变量可以是连续的也可以是离散的，回归线的性质是线性的。线性回归使用最佳的拟合直线（回归线）在因变量Y和一个或多个自变量之间建立一种关系。
```R
y = a + bx + c(残差) 
其中，a是回归系数1（alpha1）,b是回归系数2（alpha2），c是残差，也就是理论值与观测值的偏差，是一个不可观测的随机变量，或称为随机误差项。
```

# 回归系数的估计
线性模型中最重要的就是在给定的数据下，如何求得线性模型的回归系数，即上式中的a和b。统计学中通过最小二乘法求得线性回归系数的估计值，其基本思想就是在模型的随机误差平方和最小的情况下 **通过最小化每个数据点到线的垂直偏差平方和来计算最佳拟合线（回归线）**，最终求出alpha2、alpha1。
# 数学原理解析
！[图解数学原理](https://github.com/Makemore2014/RegressionAnalysis/blob/master/pic/math1.png)
